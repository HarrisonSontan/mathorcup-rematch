{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResUNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"torch ==\", torch.__version__)\n",
    "print(\"torchvision ==\", torchvision.__version__)\n",
    "\n",
    "print(\"CUDA availiable == %s\" % (torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINUX JUPYTER\n",
    "# !apt-get update\n",
    "# !apt-get install -y libgl1-mesa-glx\n",
    "\n",
    "# !pip config set global.index-url https://mirrors.aliyun.com/pypi/simple\n",
    "# !pip install scikit-learn\n",
    "# !pip install opencv-python\n",
    "# !pip install ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义ISBI_LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from model.resunet_model import Resnet_Unet\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class ISBI_Loader(Dataset):\n",
    "    def __init__(self, data_path=None, data_lst=None, use_augment=True):\n",
    "        if data_path is not None:\n",
    "            # 初始化函数，读取所有data_path下的图片\n",
    "            self.data_path = data_path\n",
    "            self.imgs_path = glob.glob(os.path.join(data_path, \"images/*.jpg\"))\n",
    "\n",
    "        if data_lst is not None:\n",
    "            # 直接载入\n",
    "            self.imgs_path = data_lst\n",
    "\n",
    "        # 预处理方法\n",
    "        self.use_augment = use_augment\n",
    "\n",
    "    def augment(self, image, flipCode):\n",
    "        # 使用cv2.flip进行数据增强，filpCode为1水平翻转，0垂直翻转，-1水平+垂直翻转\n",
    "        flip = cv2.flip(image, flipCode)\n",
    "        return flip\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 根据index读取图片\n",
    "        image_path = self.imgs_path[index]\n",
    "\n",
    "        # 根据image_path生成label_path\n",
    "        label_path = image_path.replace(\"images\", \"mask\")\n",
    "        label_path = label_path.replace(\".jpg\", \".png\")\n",
    "\n",
    "        # 读取训练图片和标签图片\n",
    "        image = cv2.imread(image_path)\n",
    "        label = cv2.imread(label_path)\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        label = cv2.resize(label, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # label转为单通道\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 处理标签，将像素值为255的改为1\n",
    "        if label.max() > 1:\n",
    "            label = label / 255\n",
    "\n",
    "        # 随机进行数据增强，为3时不做处理\n",
    "        if self.use_augment:\n",
    "            flipCode = random.choice([-1, 0, 1])\n",
    "\n",
    "            if flipCode != 2:\n",
    "                image = self.augment(image, flipCode)\n",
    "                label = self.augment(label, flipCode)\n",
    "            elif flipCode == 2:\n",
    "                kernel_size = (random.choice([1, 3]), random.choice([1, 3]))\n",
    "                sigma = random.choice([1, 2, 3])\n",
    "                image = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "\n",
    "        # 转换为tensor并标准化\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "        image_tensor = transform(image)\n",
    "        \n",
    "        # label_tensor = transform(label)\n",
    "        label_tensor = label.reshape(1, label.shape[0], label.shape[1])\n",
    "\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回训练集大小\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_files import *\n",
    "\n",
    "# 设置模型参数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 创建 resunet 网络实例\n",
    "model = Resnet_Unet(BN_enable=True, resnet_pretrain=False).to(device)\n",
    "\n",
    "# 续训练(Fine-tuning)权重加载\n",
    "fine_tuning_weights_dir = str(get_current_path() / \"blost_0.13408492505550385.pth\")\n",
    "# model.load_state_dict(torch.load(fine_tuning_weights_dir, map_location=device))\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.RMSprop(\n",
    "    model.parameters(), lr=0.00001, weight_decay=1e-8, momentum=0.9\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化图表\n",
    "\n",
    "# 使用qt5(vscode)\n",
    "# %matplotlib qt5\n",
    "\n",
    "# 使用widget(linux jupyter)\n",
    "%matplotlib widget\n",
    "\n",
    "from utils_plot import Myplot\n",
    "\n",
    "plot = Myplot(2, 2)\n",
    "\n",
    "# plot.axes[1, 1].remove()\n",
    "\n",
    "plt_epochs = []\n",
    "\n",
    "plt_trainloss = []\n",
    "plt_valloss = []\n",
    "\n",
    "plt_trainacc = []\n",
    "plt_valacc = []\n",
    "\n",
    "plt_tpr = []\n",
    "plt_fpr = []\n",
    "\n",
    "plt_f1 = []\n",
    "\n",
    "plot.save(\"./result/figure.png\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "epochs = 50\n",
    "batch_size = 2\n",
    "dataset_path = get_current_path() / \"dataset\" / \"prepare\"\n",
    "\n",
    "# 最优数值\n",
    "best_loss = float(\"inf\")\n",
    "best_accuracy = 0\n",
    "best_f1 = 0\n",
    "\n",
    "# 累计epochs\n",
    "accumulate_epochs = 0\n",
    "\n",
    "# 创建 KFold 对象，将数据集划分为 K 个折叠\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# 获取训练集列表\n",
    "k_fold_lst = get_file_list(dataset_path / \"images\")\n",
    "k_fold_lst = [str(file_pathobj) for file_pathobj in k_fold_lst]\n",
    "\n",
    "# 循环进行 K 次交叉验证\n",
    "for fold_index, (train_index, val_index) in enumerate(kf.split(k_fold_lst)):\n",
    "    # 根据索引划分训练集和验证集\n",
    "    train_lst = [k_fold_lst[i] for i in train_index]\n",
    "    val_lst = [k_fold_lst[i] for i in val_index]\n",
    "\n",
    "    # 加载训练集\n",
    "    isbi_tra_dataset = ISBI_Loader(data_lst=train_lst)\n",
    "    train_loader = DataLoader(\n",
    "        dataset=isbi_tra_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    isbi_val_dataset = ISBI_Loader(data_lst=val_lst)\n",
    "    val_loader = DataLoader(\n",
    "        dataset=isbi_val_dataset, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"fold:{:.0f} train_cnt:{:.0f} val_cnt:{:.0f}\".format(\n",
    "            fold_index, len(train_loader), len(val_loader)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 开始训练\n",
    "    for epoch in range(epochs):\n",
    "        print(\n",
    "            \"Epoch: {:.0f} Accumulate epochs: {:.0f}\".format(epoch, accumulate_epochs)\n",
    "        )\n",
    "\n",
    "        # 训练模式\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "\n",
    "        train_acc = 0.0\n",
    "        train_tptn = 0.0\n",
    "        train_samples = 0.0\n",
    "\n",
    "        # 按照batch_size开始训练\n",
    "        for image, label in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 将数据拷贝到device中\n",
    "            image = image.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            # print(\"image:\", image.shape)\n",
    "\n",
    "            # 使用网络参数，输出预测结果\n",
    "            pred = model(image)\n",
    "\n",
    "            # print(\"pred:\", pred.shape, \" label:\", label.shape)\n",
    "\n",
    "            # 计算loss\n",
    "            loss = criterion(pred, label)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 二值化\n",
    "            pred_binary = torch.zeros_like(pred)\n",
    "            pred_binary = torch.where(pred >= 0.5, 1, 0)\n",
    "\n",
    "            # 计算ACC\n",
    "            train_tptn += (pred_binary == label).sum().item()\n",
    "            train_samples += (pred_binary == 1).sum().item() + (\n",
    "                pred_binary == 0\n",
    "            ).sum().item()\n",
    "            train_acc = train_tptn / train_samples\n",
    "\n",
    "            # 更新参数\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 求epoch平均loss\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        print(\n",
    "            \"[{:.0f}/{:.0f}] LOSS: {:.3f} ACC:{:.3f} TP:{:.0f} TOTAL:{:.0f}\".format(\n",
    "                epoch + 1,\n",
    "                epochs,\n",
    "                train_loss,\n",
    "                train_acc,\n",
    "                train_tptn,\n",
    "                train_samples,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 验证模式\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "\n",
    "        val_acc = 0.0\n",
    "        val_tptn = 0.0\n",
    "        val_samples = 0.0\n",
    "\n",
    "        tp = 0.0\n",
    "        fp = 0.0\n",
    "        tn = 0.0\n",
    "        fn = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_image, val_label in tqdm(val_loader):\n",
    "                val_image = val_image.to(device=device, dtype=torch.float32)\n",
    "                val_label = val_label.to(device=device, dtype=torch.float32)\n",
    "\n",
    "                # 预测\n",
    "                val_pred = model(val_image)\n",
    "\n",
    "                # 计算loss\n",
    "                loss = criterion(val_pred, val_label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # 二值化\n",
    "                val_pred[val_pred >= 0.5] = 1\n",
    "                val_pred[val_pred < 0.5] = 0\n",
    "\n",
    "                # 计算TP、FP、TN、FN\n",
    "                tp += ((val_pred == 1) & (val_label == 1)).sum().item()\n",
    "                fp += ((val_pred == 1) & (val_label == 0)).sum().item()\n",
    "                tn += ((val_pred == 0) & (val_label == 0)).sum().item()\n",
    "                fn += ((val_pred == 0) & (val_label == 1)).sum().item()\n",
    "\n",
    "        # 计算准确率\n",
    "        val_acc = (tp + tn) / (tp + fp + tn + fn + 1e-8)\n",
    "\n",
    "        # 计算精确率\n",
    "        val_prec = tp / (tp + fp + 1e-8)\n",
    "\n",
    "        # 计算召回率\n",
    "        val_rec = tp / (tp + fn + 1e-8)\n",
    "\n",
    "        # 计算F1分数\n",
    "        val_f1 = 2 * (val_prec * val_rec) / (val_prec + val_rec + 1e-8)\n",
    "\n",
    "        # 求epoch平均loss\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(\"vLoss:{:.3f}, vAccuracy:{:.3f}\".format(val_loss, val_acc))\n",
    "\n",
    "        # 保存最优模型\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                \"./result/lost_{:.3f}_k{:.0f}_e{:.0f}.pth\".format(\n",
    "                    val_loss, fold_index, accumulate_epochs\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                \"./result/acc_{:.3f}_k{:.0f}_e{:.0f}.pth\".format(\n",
    "                    val_acc, fold_index, accumulate_epochs\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        if val_f1 > (best_f1 + 0.02) and val_f1 > 0.80:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                \"./result/f1_{:.3f}_k{:.0f}_e{:.0f}.pth\".format(\n",
    "                    val_f1, fold_index, accumulate_epochs\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        torch.save(model.state_dict(), \"./result/latest.pth\")\n",
    "\n",
    "        # 画图\n",
    "        plt_trainloss.append(train_loss)\n",
    "        plt_trainacc.append(train_acc)\n",
    "        plt_valloss.append(val_loss)\n",
    "        plt_valacc.append(val_acc)\n",
    "        plt_f1.append(val_f1)\n",
    "        plt_epochs.append(accumulate_epochs)\n",
    "        plot.plot_learning_curve(0, 0, plt_epochs, plt_trainloss, plt_valloss)\n",
    "        plot.plot_accuracy_curve(0, 1, plt_epochs, plt_trainacc, plt_valacc)\n",
    "        plot.plot_f1_epoch_score_curve(1, 0, plt_epochs, plt_f1)\n",
    "        plot.plot_confusion_matrix(1, 1, tp, fp, tn, fn)\n",
    "        plot.fresh()\n",
    "        plot.save(\"./result/figure.png\")\n",
    "\n",
    "        accumulate_epochs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from utils_metrics import compute_mIoU, show_results\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from model.unet_model import UNet\n",
    "\n",
    "from utils_files import *\n",
    "\n",
    "def unet_predict(test_dir, pred_dir):\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.makedirs(pred_dir)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 加载网络，图片单通道，分类为1。\n",
    "    net = UNet(n_channels=1, n_classes=1)\n",
    "\n",
    "    # 将网络拷贝到deivce中\n",
    "    net.to(device=device)\n",
    "\n",
    "    # 加载模型参数\n",
    "    net.load_state_dict(torch.load(\"unet_best_model.pth\", map_location=device))\n",
    "\n",
    "    # 测试模式\n",
    "    net.eval()\n",
    "    print(\"Load model done\")\n",
    "\n",
    "    img_names = os.listdir(test_dir)\n",
    "    image_ids = [image_name.split(\".\")[0] for image_name in img_names]\n",
    "\n",
    "    for image_id in tqdm(image_ids):\n",
    "        # 获取文件列表\n",
    "        image_path = os.path.join(test_dir, image_id + \".jpg\")\n",
    "        img = cv2.imread(image_path)\n",
    "        origin_shape = img.shape\n",
    "\n",
    "        # 转为灰度图\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.resize(img, (512, 512))\n",
    "\n",
    "        # 转为batch为1，通道为1，大小为512*512的数组\n",
    "        img = img.reshape(1, 1, img.shape[0], img.shape[1])\n",
    "\n",
    "        # 转为tensor\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "\n",
    "        # 将tensor拷贝到device中\n",
    "        img_tensor = img_tensor.to(device=device, dtype=torch.float32)\n",
    "\n",
    "        # 预测\n",
    "        pred = net(img_tensor)\n",
    "\n",
    "        # 提取结果\n",
    "        pred[pred >= 0.5] = 255\n",
    "        pred[pred < 0.5] = 0\n",
    "\n",
    "        pred = np.array(pred.data.cpu()[0])[0]\n",
    "        pred = cv2.resize(\n",
    "            pred,\n",
    "            (origin_shape[1], origin_shape[0]),\n",
    "            interpolation=cv2.INTER_NEAREST,\n",
    "        )\n",
    "\n",
    "        cv2.imwrite(os.path.join(pred_dir, image_id + \".png\"), pred)\n",
    "\n",
    "    print(\"Get predict result done\")\n",
    "\n",
    "\n",
    "dataset_path = get_current_path() / \"dataset\" / \"test\"\n",
    "\n",
    "unet_predict(test_dir=str(dataset_path / \"images\"), pred_dir=str(dataset_path / \"pred\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_metrics import compute_mIoU, show_results\n",
    "from utils_files import *\n",
    "dataset_path = get_current_path() / \"dataset\" / \"prepare\"\n",
    "\n",
    "gt_dir = str(dataset_path / \"mask\")\n",
    "pred_dir = str(dataset_path / \"pred\")\n",
    "test_dir = str(dataset_path / \"images\")\n",
    "result_dir = str(dataset_path / \"result\")\n",
    "\n",
    "img_names = os.listdir(test_dir)\n",
    "image_ids = [image_name.split(\".\")[0] for image_name in img_names]\n",
    "\n",
    "num_classes = 2\n",
    "name_classes = [\"background\", \"potholes\"]\n",
    "\n",
    "print(\"Get mIoU\")\n",
    "print(gt_dir)\n",
    "print(pred_dir)\n",
    "print(num_classes)\n",
    "print(name_classes)\n",
    "hist, IoUs, PA_Recall, Precision = compute_mIoU(\n",
    "    gt_dir, pred_dir, image_ids, num_classes, name_classes\n",
    ")\n",
    "# print(hist)\n",
    "print(\"Get mIoU done.\")\n",
    "show_results(result_dir, hist, IoUs, PA_Recall, Precision, name_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# 计算面积百分比\n",
    "from utils_metrics import only_percentage\n",
    "from utils_files import *\n",
    "\n",
    "dataset_path = get_current_path() / \"dataset\" / \"test\"\n",
    "\n",
    "gt_dir = str(dataset_path / \"mask\")\n",
    "pred_dir = str(dataset_path / \"pred\")\n",
    "test_dir = str(dataset_path / \"images\")\n",
    "result_dir = str(dataset_path / \"result\")\n",
    "\n",
    "img_names = os.listdir(test_dir)\n",
    "image_ids = [image_name.split(\".\")[0] for image_name in img_names]\n",
    "\n",
    "only_percentage(pred_dir, image_ids)\n",
    "print(\"ok\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
